<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <title>Balance: The holy trinity of music taste</title>
    <style>
      body{
        font-family: -apple-system, BlinkMacSystemFont,
            "Segoe UI", "Roboto", "Oxygen", "Ubuntu", "Cantarell",
            "Fira Sans", "Droid Sans", "Helvetica Neue",
            sans-serif;
        font-size: 1.1em;
        max-width: 50em;
        margin: 3em 0 1em 5%;
          }
      blockquote{
        border-left: 2px solid black;
        padding: 2px .7em .5em;
        -webkit-margin-start: 7px;
      }
      blockquote p{
        font-style: italic;
      }
      .flower{
        max-width: 100%;
        width: 350px;
      }
      .diagram{
        max-width: 100%;
        width: 400px;
      }
    </style>
  </head>
  <body>
    <h1>Balance: The holy trinity of music taste</h1>
    <p>By Sanjay Poyzer, 2011</p>
    <span>with thanks to my thesis tutor, Dr Chris Kennet</span>
    <nav>
      <h3>Sections</h3>
      <ol>
        <li>
          <a href="#s1">(Music is good.)</a>
        </li>
        <li>
          <a href="#s2">(Good is subjective.)</a>
        </li>
        <li>
          <a href="#s3">(Subjectivity is a personal experience.)</a>
        </li>
        <li>
          <a href="#s4">(Experiences are dictated by our memories.)</a>
        </li>
        <li>
          <a href="#s5">(Memories become emotions.)</a>
        </li>
        <li>
          <a href="#s6">(Emotions create music.)</a>
        </li>
      </ol>
    </nav>

    <h2>Introduction</h2>
    <p>
      Music analysis is a questionable field. Thereʼs a gap between music theorists-both popular (Kivy, 2007; Kennett, 2003; Frith, 1998, etc.) and classical (Meyer, 1989;Cooke, 1959, etc.) - and neuroscientists (Levitin, 2007, 2009a, b; Peretz & Zatorre,2005, etc.). Classicists look for a meaning behind the supposed language of music<sup id="r1"><a href="#f1">1</a></sup>, populists dismiss such notions against theories of subjectivity and neuroscientists strive for proof that it affects us all the same.<sup id="r2"><a href="#f2">2</a></sup> Music theorists from both the popular and classical worlds seem to be - using limited evidence - striving to create an instruction book for how to listen to music, (or how to understand it better at least) rather than creating a theory of what actually happens to people when we listen to music based on empirical evidence. The neuro-scientists do seem to be closer to doing so, but havenʼt presented their findings in a practical context, unsurprisingly given how new the field is.<sup id="r3"><a href="#f3">3</a></sup> Neuroscience has come much further in studying vision, as other animals process visual stimuli in much the same way we do, (Abbot, 2002) but we are the only animals that fully appreciate music.<sup id="r4"><a href="#f4">4</a></sup>
    </p>
    <p>
      In general, popular music studies deals with conscious decisions made when when choosing musical preferences in broad strokes like genre. But the captivation that certain songs hold over us is a much more individual experience, which is why I have chosen to focus more on neuroscience.
    </p>
    <p>
      The aim of my thesis is better understanding of the value of music to people, in the hope of helping both musicians (myself included) to create better music and the music industry to market and monetize music better. Cross (2004) wrote that music gathers ʻmeaning from the contexts within which it happens and in turn [contributes] meaning to those contextsʼ<sup id="r5"><a href="#f5">5</a></sup>. My ʻHoly Trinityʼ Model hopes to explain how this “floating intentionality” (ibid) happens and becomes our individual experience of a piece of music.
    </p>
    <p>
      As my background is in creating music rather than writing about it, I come from none of the above camps. This is why Iʼve strived to come up with a model which uses the undeniable truths from both areas of study (music theory and music neuroscience) which hopes to be practically useful to other musicians. The research presented within this thesis proves the fact that (while my ʻHoly Trinity theoryʼ within proves how) a certain piece of music can give somebody an indescribable feeling of divinity, while others wouldnʼt even glorify the same collection of sounds by calling it music.
    </p>
    <p>
      It is generally accepted by Classical theorists such as Kivy (2007) that music is better appreciated and enjoyed by those who “understand” what they listen to. There is a syntax that one must learn to truly comprehend the meaning. Meanwhile Pop is created for people to enjoy without thinking about it at all.
    </p>
    <p>
      This thesis deals primarily with that initial, gut reaction - how people feel rather than what they think about music.
    </p>

    <h2 id="s1">Section 1: Iʼve Got A Feeling (Music is good.)</h2>

    <blockquote>
      <p>
        “Without music, life would be an error.”
      </p>
      <footer>
        - Nietzsche, 1889
      </footer>
    </blockquote>
    <blockquote>
      <p>
        “Music brings about similar physical responses in different people at the same time. This is why it is able to draw groups together and create a sense of unity. It does not matter that a dirge or funeral march may be appreciated in a different way by a musician and by an unsophisticated listener. They will certainly be sharing some aspects of the same physical experience at the same moment, as well as sharing the emotions aroused by the funeral itself. Music has the effect of intensifying or underlining the emotion which a particular event calls forth, by simultaneously co-ordinating the emotions of a group of people.”
      </p>
      <footer>
        - Storr, 1992, pp.24
      </footer>
    </blockquote>
    <p>
      Almost every piece in my bibliography talks about musicʼs unprecedented effect on people, with Meyer (1961) being one notable example. Meyerʼs work fails to cite any evidence of musicʼs power beyond behavioral observations,<sup id="r6"><a href="#f6">6</a></sup> yet Iʼd be extremely surprised if anyone reading this thesis is yet to experience the overwhelming feeling that has caused music to have such an important place in human history and culture. Rest assured though, since Meyerʼs work there have been many studies analyzing what happens to peopleʼs brains when they are in love with a piece of music and the phenomenon of the “chills” effect is very much a real one. In fact, neuro-imaging techniques and behavioral studies have revealed that with specific musical stimuli, the same neural substrates are activated as “biologically significant stimuli such as food and drug abuse” (Peretz & Zatorre, 2005, pp. 99) and there is even evidence for the existence of neural networks specialized for the processing of scale structure in melodies. (ibid, pp.93) resulting in widening acceptance by neuroscientists that music must have “adaptive benefits” due to there being space in the brain set aside solely for itʼs appreciation. (Peretz, 2002, pp.163) (Levitin, 2006, 2009a, b) Music is even used for therapy, with chosen music even having a calming effect on acute psychotic episodes. (Morgan et al, 2010) There are even extreme examples, such as the sufferers of musicogenic epilepsy (one patient had severe seizures only when classical music was played to her and brain scans showed that her memory centres were active (Peretz, 2002, pp.160)), which point toward the strongest emotional reactions towards music coming from itʼs powerful associative qualities.
    </p>
    <blockquote>
      <p>
        “Music, or musical sounds of some variety, are so interwoven with human life that they probably played a greater part in prehistory than can ever be determined.”
      </p>
      <footer>
        - Storr, 1992, pp.1
      </footer>
    </blockquote>
    <p>
      In fact many neuroscience articles in my bibliography show that music affects increasingly varied aspects of the brain. (Large and Snyder, 2009) One example being the dispelling of previous thoughts about the right side of the brain processing music, with findings that anaesthesia to the left hemisphere caused loss of singing ability, speech comprehension and production where the right hemisphere anaesthetised disabled comprehension of pitch and tone. (Hachinski & Hachinski, 1994) (Tramo, 2001) (Storr, 1992, pp. 36)
    </p>
    <blockquote>
      <p>
        “PET-based studies demonstrate that listening to the music activates the right hemisphere (thought to be the more “intuitive” part of the brain) in inexpert listeners, whereas the left hemisphere, the “rational” side, is instead activated in musicians. Moreover, the right hemisphere perceives timbre and melody, whereas the left one analyses rhythm and pitch, the “mathematical” and “syntactical” face of music, strictly interacting with the language areas. There is no doubt that the same Mozartʼs Symphony is perceived with a different way and different depth when listened to by a naïve listener or by a Mozart lover, or by a great Mozart conductor. It has been demonstrated that the naïve listener only exhibits a “gestaltic” perception of music.”
      </p>
      <footer>
        - Cervellin & Lippi, 2011
      </footer>
    </blockquote>
    <p>
      Music immerses and stimulates many parts of the brain, and this is the first step to understanding why it is so important. But this is not the effect of all music, all the time on all people...
    </p>
    <p>
      So what exactly makes music good?
    </p>
    <h2 id="s2">Section 2: Across The Universe (Good is subjective.)</h2>
    <blockquote>
      <p>
        “Nothing is either good, or bad, but thinking makes it so.”
      </p>
      <footer>
        - Shakespeare, 1600 (Hamlet, Act 2, Scene 2)
      </footer>
    </blockquote>
    <blockquote>
      <p>
        “Beauty is in the limbic system of the beholder.”
      </p>
      <footer>
        - Seymour, 2011
      </footer>
    </blockquote>
    <blockquote>
      <p>
        "The thing about sound is that from somewhere else the sound is always different."
      </p>
      <footer>
        - Maconie, 1997: 34
      </footer>
    </blockquote>
    <blockquote>
      <p>
        “Music is by essence perceptually driven. Unlike speech, music is not associated with a fixed semantic system, although it may convey meaning through other systems, such as emotional analysis and associative memories.”
      </p>
      <footer>
        Peretz & Satorre, 2005
      </footer>
    </blockquote>

    <p>
      This analysis of music as a “phenomenon of subjective human experience” as opposed to a laboratory controlled stimulus (Altenmüller, 2001) is pertinent to understanding itʼs effects, but often neglected.
    </p>
    <p>
      Narmourʼs (1989) Implication-Realisation model hypothesised that “intervallic continuation, registral direction, and specific pitch (when the mode is known) are all separately subject to cognitive prediction and is dependant on laws of implication and expectancy. Moreover, in order to qualify as a realisation the model says also that where a melodic realisation is to occur (place) and how long it lasts (time) are essential to any understanding of implication.” But this model would only fit the small portion of the worldʼs population who are trained to the semantics of western Classical music. This is because music can never be translated or deciphered in any universal way as the exact meaning(s) that have been written about is only ever perceived -or better “felt”- by the writers [listener] in question. (Altenmüller, 2001)
    </p>
    <p>
      Neuroscience shows that music does have some similar effects on our brains, but exactly how much has not yet been found. Rhythm, for example, is generally processed more similarly than other features of music such as melody, as it utilises more instinctive parts of the brain such as the core auditory and motor areas.<sup id="r9"><a href="#f9">9</a></sup> In the talk released as “Notes & Neurons”, itʼs shown how western listeners can adapt to eastern scales9 fairly quickly just as Krumhansl (2000) shows that people adapt fairly quickly to the North Sami Yoik tradition when tested. The studies use different brain imaging processes, including the SOM Model, so the fact that they both come to the same result is substantial- it seems to suggest that we all hear music in the same way but the crucial variable here is the listenerʼs experience with the music. In both of these studies, the listeners became accustomed to the music after repeatedly being played it. This suggests that music can be learnt like a language and is an important point I will come back to.
    </p>
    <p>
      So if music is a language, can everyone understand it?
    </p>
    <h2 id="s3">Section 3:
We Can Work It Out or Roll Over Beethoven (Subjectivity is a personal experience.10)</h2>
    <blockquote>
      <p>
        “Subjectivity measures nothing consistently.”
      </p>
      <footer>
        Beta, 2011 11
      </footer>
    </blockquote>
    <blockquote>
      <p>
        "No engineer can determine for sure where one sound ends and another begins, either in space or time. Nevertheless sounds are differentiated, they can be located, and they can be analysed by you and me, simply by listening."
      </p>
      <footer>
        Maconie, 1997: 35
      </footer>
    </blockquote>
    <p>
      The notion that music can have an objective meaning and worth is an outdated, western classical ideal. Itʼs been said that Music is more widely "understood"12 because it requires knowledge of syntax13, rather than semantics like natural language,14 (Kivy, 2006: 216) while neuro-studies have shown that we use a syntax to understand music through activity in the Brocaʼs area, typically used for language processing. (Patel, 2003; Holden, 2001) Scans show activity in this area is increased even further when listening to conventional chord sequences as opposed to unexpected notes. (ibid)
    </p>
    <blockquote>
      <p>
        “But what use is music? Music can certainly be regarded as a form of communication between people; but what it communicates is not obvious. Music is not usually representational: it does not sharpen our perception of the external world, nor, allowing for some notable exceptions, does it generally imitate it. Nor is music propositional: it does not put forward theories about the world or convey information in the same way as does language.”
      </p>
      <footer>
        Storr, 1992, pp.2
      </footer>
    </blockquote>
    <p>
      A study investigating semantic priming of words using sentences and music showed that concrete association of music to words was only evident when the sound in question actually resembled the word (e.g., birdʼs tweeting primed the word ʻbirdʼ) or qualities of objects (e.g., low tones associated with basement). The point of the experiment was to see how the meaning of music could be conveyed by music alone, and it concluded that music uses the same brain areas as language to convey meaning, showing that there must be a syntax that is learnt for full appreciation. (Koelsch, et al, 2004)
    </p>
    <p>
      Charles Darwin popularly hypothesised that music may have been a protolanguage in ancient times. (Cervellin & Lippi, 2011) "...given the similarities between music and language, it's not surprising that there has been a running debate for more than two hundred years as to whether they evolved in tandem or independently- and, if the latter, which came first. Darwin speculated that musical tones and rhythms were used by our half-human ancestors, during the season of courtship... excited by love... jealousy, rivalry and triumph" (Sachs, 2007: x)
    </p>
    <p>
      The music-language metaphor is a tenuous one (not to mention a tired one) as there are no comparable features. A word is not like a chord because chords are never defined to any standards. (Although classical composers have strived to.15) This important, inherent difference between language and music points out the real relationship between them. Much like sexual intercourse and foreplay, one has an obvious function whereas the other is a much more subjective pleasure, but they both follow the same basic principles and participants, both can be pleasurable in different but similar ways, and one things for sure, they definitely compliment each other extremely well.
    </p>
    <p>
      Music and language do not use the exact same neural networks however, studies show, (Groussard et al., 2010) but they do “share the same executive and selection processes, which are subserved by the left interior frontal cortex. (ibid)
    </p>
    <blockquote>
      <p>
        “The assumption of an intimate connection between music and speech is corroborated by the findings of overlapping and shared neural resources for music and language processing in both adults and children. In this respect it appears that the human brain, at least at an early age, does not treat language and music as strictly separate domains, but rather treats language as a special case of music.”
      </p>
      <footer>
        - Koelsch, 2005
      </footer>
    </blockquote>
    <blockquote>
      <p>
        “Linguistic analysts distinguish prosodic features of speech from syntactic: stress, pitch, volume, emphasis, and any other features conveying emotional significance, as opposed to grammatical structure of literal meaning. There are many similarities between prosodic communication and music. Infants respond to the rhythm, pitch, intensity, and timbre of the motherʼs voice; all of which are part of music.”
      </p>
      <footer>
        Storr, 1992, pp.9
      </footer>
    </blockquote>
    <p>
      It's worth noting when talking about the ambiguity of music versus the exactness of language, especially in relation to poetry and lyrics, that everyday language is actually more often than not allowed to be abstract. We have set definitions for words, but even setting aside the fact that there are various versions of these definitions (a paradox of modern language really - Should a definition not be definite?) we rarely refer to them. In practice, people much more often than not learn what words mean through experienced context. Much like musical phrases/motifs/other attributes. This is of course the reason why definitions constantly change; because they are constantly reinvented by people using them in slightly different contexts.
    </p>
    <p>
      Cooke (1959) posits that “our culture is impoverished” by our lack of defined syntax for understanding music and attempts to define one in “The Language Of Music”. This is not only impossible because of the nature of music and how we appreciate it as described above, it would actually destroy itʼs essence.
    </p>
    <p>
      In regards to popular music, “most people if asked what a song ʻmeansʼ refer to the words” (Frith, 1998: 158) so pop music has a level of meaning which instrumental music does not. Lyrics though, are essentially poems which have been given a melody. There are ways in which their combination can be given meaning which is more than the sum of itʼs parts, not to mention factors which can only be experienced through the combination of those such as performance nuances and accent, (ibid -182) but for the most part music and lyrics can be separated into two different cognitions. In any case, although many parts of this thesis may apply to poetry it is really cognition of music that this thesis primarily deals with.
    </p>
    <p>
      In my own personal experience, I find it hard to concentrate on intense reading or writing sessions when listening to music to lyrics, but impossible to concentrate if there is background talking without music or a capella music in English (the only language I speak). I found a good solution is to listen to instrumental music. I then found that instrumental music, when played on my first instrument, guitar, is still distracting (though not as much as the first two stimuli). My research suggests this is because of more of my brain being used to process the semantical information of a guitar being played- My mirror neurons (Levitin, 2009a) are subconsciously telling me which string is being played, which position the lick is being played in, etc. So even before I start having any emotional feelings towards the music, how much it affects me is already being decided by who I am.
    </p>
    <h2 id="s4">Section 4: In My Life (Experiences are dictated by our memories.)</h2>
    <p>
      So where does this connection with music start exactly?
    </p>
    <p>
      Obviously, some people are more musically inclined at a young age than others, however studies show there is no neurological difference between childrenʼs brains who choose to study music and those who do not. (Norton et al., 2005) In fact, even 4 month old babies, (and besides the point, but also even rats and starling) have shown they can tell the difference between consonance and dissonance. (Tramo, 2001) It goes back even further though, with studies showing there is “a neuronal architecture serving the processing of music already present at birth”, suggesting we start to become accustomed to deciphering music in utero. (Perani et al, 2010)
    </p>
    <p>
      After citing The Independent on Sunday's 16 January 1994's article '"Neighbours" Theme Learned in the Womb" Maconie goes further in depth into how "Babies can hear, are stimulated by, and respond to sound before birth. The implication that babies not only hear, but remember what they have heard before, long before our earliest memories, shows the scope of our subconscious relationship with music. (Maconie, 1997: 37-39)
    </p>
    <blockquote>
      <p>
        “Since infants in the womb react both to unstructured noise and to music with movements which their mothers can feel, it seems likely that auditory perception prompts the babyʼs first realisation that there is something beyond itself to which it is nevertheless related. After birth, vocal interchange between mother and infant continues to reinforce mutual attachment, although vision soon becomes equally important. The crooning, cooing tones and rhythms which most mothers use when addressing babies are initially more significant in cementing the relationship between them than the words which accompany these vocalisations.This type of communication continues throughout childhood... Moreover, although relationships between adults usually involve verbal interchange, they do not always do so.”
      </p>
      <footer>
        Storr, 1992, pp.9
      </footer>
    </blockquote>
    <p>
      Itʼs also been said that we are born with an innate “number” sense, an approximate sense of arithmetic that is independent of language and can be mapped to parietal lobe circuits. This has been linked to early ability to process music, which after all, can much easier be turned into mathematics then speech recognition can (in non-pitched languages, at least.) (Balter, 2001)
    </p>
    <p>
      The idea of preference from birth is related to Dutton (2011)ʼs ʻDarwinian Beautyʼ, of which our feelings towards certain things in the world are in our genes. This idea is twinned with the more popularly held idea that beauty is a cultural preference. The idea has not been discussed in practical relation to music however, and although it is worth remembering just how deep our subconscious feelings can go, thus far there is no evidence to suggest we inherit specific music taste - Just a vague preference for consonance.
    </p>
    <p>
      Emotional connection with music is dependant upon longterm musical memory creating associations with the piece through the musical semantic memory system, as defined by Groussard et al (2010): “It is musical semantic memory that allows us to experience a strong feeling of knowing when listening to music (reflecting familiarity processes) and gives us the ability to hum the subsequent notes of a melody, or in some cases retrieve the title, composer or performer of a particular excerpt (corresponding to identification).”
    </p>
    <h2 id="s5">Section 5:
Iʼm Happy Just To Dance With You (Memories create our emotions.)</h2>
    <p>
      Snyder (2000:7) shows how our entire perceptual awareness is created through a relationship between our ʻEchoic Memoryʼ and ʻLong-Term Memoryʼ called Perceptual Binding and Feature Extraction. In essence, we perceive things how we do because of how theyʼve been perceived before - creating an important feedback loop. What breaks our feedback loop and contributes to our opinions of pieces of music changing is called by Snyder a “nuance”. This is an important idea to keep in mind when I come to my Holy Trinity Model in Section 6.
    </p>
    <p>
      Emotions are states of the brain which arise from environmental stimuli with the evolutionary function of reminding oneself of previous encounters with the given stimuli. Our mood, therefore, is always constantly dictated by the environment we find ourselves in, including the aural environment. This is how we perceive music.
    </p>
    <blockquote>
      <p>
        "Perception is mental activity arising from the interaction of the environment and the senses. The environment includes other people and their conversation as well as light and shade, heat and cold. The mental activity that gives rise to perceptions of the world is not so much something we choose to do, as behavior forced upon us that we gradually learn to control. We are obliged to perceive because we cannot prevent our sense from responding to everyday stimuli. Though everybody has the same responses, not everyone has the same perceptions. Senses are what you are born with, whereas perception is something you learn, a skill at interpreting sense responses that is developed and refined as one grows."
      </p>
      <footer>
        - Maconie, 1997: 28
      </footer>
    </blockquote>
    <blockquote>
      <p>
        “Listening to the same music in different situations, with different purposes and with different intensity, will affect... the experience.”
      </p>
      <footer>
        - Kennet, 2003:197
      </footer>
    </blockquote>
    <p>
      Richard Seymour (2011) explained how "The wiring of the sensory apparatus to those bits is shorter than the bits that have to pass through the 'thinky bit' - the cortex." Essentially, we feel before we think. And although, as Seymour notes, strong feelings appear to occur more in the solar plexus than anywhere else, science would suggest that our emotions really happen in the brain. These subconscious reactions to music are what weʼre really interested in when we talk about the majority of peopleʼs connection with music.
    </p>
    <p>
      Semour (ibid) also presented the following picture in his talk:
    </p>
    <img src="flower.png" class="flower" alt="A drawing of a flower, which at first glance at least, is unremarkable." />
    <p>
      He noted the audienceʼs initial reaction to the drawing, asking them “Is it beautiful? Is it exciting?” resulting in “some bored looking gentlemen.” Seymour then told them that the picture was in fact, “the last act on Earth of a little girl called Heidi, 5 years old, before she died of cancer to the spine.”
    </p>
    <p>
      When put like this, it seems unquestionable to me that our knowledge of things changes how we feel about them. This is as true to music as it to art/design, and that fact is why music is much more akin to art than language - Itʼs not just about simply communicating, but about communicating subjective emotions.
    </p>
    <h2 id="s6">Section 6:
Why Donʼt We Do It In The Road? or Come Together (Balance: The Holy Trinity Theory)
(Emotions create music.)</h2>
    <blockquote>
      <p>
        “Happiness is not a matter of intensity but of balance, order, rhythm and harmony.”
      </p>
      <footer>
        - Thomas Merton, 1915-1968
      </footer>
    </blockquote>
    <p>
      So far Iʼve established and verified with modern neuroscience some truisms about how we experience music:
    </p>
    <ol>
      <li>
        Music can have a profound effect on people.
      </li>
      <li>
        Different music can have different effects on different people.
      </li>
      <li>
        This is because any given experience with a given piece of music is rooted in all experiences with all music before that one.
      </li>
      <li>
        This method of using memory at a subconscious level to make sense of music as a stimulus is comparable to how we cognise language.
      </li>
      <li>
        Because of this, it can be appropriate to treat music as a sort of communication, or at least to use elements of communicative ideas in analysing our relationship with it.
      </li>
      <li>
        One feature of music that is prevalent and not in language very much at all, is emotion. This is why music is an art and not a language.
      </li>
    </ol>
    <p>
      Bearing these truisms in mind, Iʼve constructed a model for understanding music, at itʼs most potent level of effecting people. The model uses the much lauded Shannonʼs Information Theory (Shannon, 1948) but takes into account an important differentiator between raw communication and art - Emotion.
    </p>
    <p>
      Information Theory had been absent from much of psychology for some time (Luce, 2003) when Cross (2004) acknowledged Shannonʼs Information Theory (1948) as important for analysing the communicative functions, methods and causes of music. He outlines how in the context of the theory, the performer is the ʻsenderʼ [of information], the listener is the ʻreceiverʼ, the air is the channel and the information being transmitted is the sonic patterns which constitute the music. However, Cross expands, not all instances of music, especially those outside of Western culture,16 have distinct senders/performers and receivers/listeners as in many cases all parties are participating in the creation of the music. Cross (ibid, pp.3) writes that “music in these [more participatory] guises does not seem as easily assimilable as is language into [Shannonʼs] model” but this misses the point of musicʼs communicative qualities.
    </p>
    <p>
      Musicʼs purpose is much more personal than simply communicating a message to others. We ʻplayʼ music, not ʻsayʼ music because the act of creating is much more akin to children hitting objects to understand their function than to an intellectual making an informed point in a debate. Music, especially the act of performing music, is about communicating with ourselves by helping ourselves understand more about, and explore, the world through our sense of hearing.
    </p>
    <h3>Introducing the holy trinity model</h3>
    <img src="diagram1.png" class="diagram" />
    <p>
      Diagram 1 illustrates the three points and the center-point between them.17 The center- point is a perfect musical experience.
    </p>
    <p>
      The model is based on three variables, which are formed entirely from a given personʼs past experiences. If a given musical experience has too much, or too little, of any of these variables then - from the listenerʼs perspective - the music is imperfect. But if the experience strikes an exact balance between Entropy, Redundancy and Emotion, it is music in itʼs superlative, divine state (as described in Section 1).
    </p>
    <p>
      Scholars such as Frith (1998: 100) have defined music as ʻorganised soundʼ, but a side effect of my theory is that it offers a new definition of music: ʻany experience inside the triangleʼ, but if a sound leans towards one of the three points too far, it loses the title of music and becomes just noise. (This is derived from the common usage of the word ʻnoiseʼ as a derogatory term for bad music.)
    </p>
    <p>
      I have said ʻexperience in these definitions instead of ʻsoundʼ because anybody can call anything they want music. This is especially pertinent in live performances where visual stimuli affect enjoyment of the musical experience just as much as auditory stimuli. However, for the experience to affect people in the same way as described in Section 1, it must strike the Balance; that is when it becomes Music as the term is commonly understood.
    </p>
    <h3>A Clarification of The Three Points</h3>
    <h4>Entropy</h4>
    <blockquote>
      <p>
        “To be challenged as well as rewarded is a fundamental principle of life. Indeed the greater the challenge, the greater the reward. You don't need to be a neuroscientist to realise that.”
      </p>
      <footer>
        - Classical Conductor Mark Wigglesworth (2011)
      </footer>
    </blockquote>
    <blockquote>
      <p>
        "If the world were not a stimulating place, we would not be aware of it."
      </p>
      <footer>
        - Maconie (1997: 29
      </footer>
    </blockquote>
    <p>
      Humans are cautious of the unknown. The ancient world that our ancestors lived in was an extremely dangerous place, so we evolved our prefrontal cortex to help work out that things that are similar to other things probably have similar effects. To this day, anything completely unusual in any sense will unsettle us. Even though, logically, we know that music (especially recorded music) can not harm us in any way, itʼs an instinctive reaction- an emotional response.
    </p>
    <p>
      The flip-side of this is that entropy is the very thing that keeps us interested in music, and in fact, all of lifeʼs experiences. Humans are constantly looking for new things to excite and stimulate the various parts of their brain, and music is one of the best ways to do so. If music is auditory cheesecake, as Pinker (1997) put it, then each song is surely a flavour, and nobody wants to eat strawberry all their life. Anybody whoʼs ever listened to mainstream radio can attest to that.
    </p>
    <p>
      This is not to mention the cultural pressures to listen to new, fashionable music, which the music industry both helps instigate and thrives upon. It is worth noting that, during puberty, these ʻEntropy taste makersʼ are more prevalent, as of course it is common for a personʼs music taste (and indeed, personality) to be defined.
    </p>
    <h4>Redundancy</h4>
    <p>
      By the same token that weird sounds will unsettle- recognisable sounds will comfort. This part of the trinity explains the phenomena of tonality and timbre, and why the observable evolution of these aspects of music in particular takes many generations, despite both our instincts and much of our culture pushing for entropy.
    </p>
    <blockquote>
      <p>
        ʻThe human brain is habituative, that is, it suppresses repetitive and expected information.ʼ
      </p>
      <footer>
        - Wieser, 2003
      </footer>
    </blockquote>
    <blockquote>
      <p>
        “Recognition involves an interaction between current experience and memory. When this interaction continually produces a perfect match, the phenomenon of habituation can occur. When we completely ʻre-cogniseʼ something, there is no longer any need to consciously process this information because it is already completely familiar to us, which usually causes this information to pass out of the focus of conscious awareness and become part of our perceptual and conceptual background. This means, not that the information is no longer being processed at all, but only that the memory activation it causes is no longer at a level that would place it in conscious awareness. Aspects of our environment to which we have habituated move into the background of awareness, but are still very much a part of the unconscious context of ongoing experience.”
      </p>
      <footer>
        - Snyder, 2000:23-24
      </footer>
    </blockquote>
    <h4>Emotion</h4>
    <p>
      This is shorthand for ʻEmotional Relevanceʼ. It could also be considered as “forces which are external to the present relationship between the listenerʼs mind and the piece of music”.
    </p>
    <p>
      Emotional relevance comprises of contextual emotional relevance (i.e. social context or other environmental/situational factors)18 and personal emotional relevance (i.e how the song relates to the listenerʼs feelings and personal dispositions). Both of these together form emotional relevance of a given experience with a piece of music.
    </p>
    <p>
      Seymour (2001) actually mentioned my three points with different wording. He talked of:
    </p>
    <ul>
      <li>
        Pathos: A factor of emotional response, related to empathy.
      </li>
      <li>
        Triumph: Related to Entropy. The realisation of an unexpected fact about what you are experiencing. Nobody would have expected that picture to be the last act of somebody, so when they found out, their brains were more alert about the drawing.
      </li>
      <li>
        Association: Related to Redundancy. Seymour references when BMW introduced lights in cars that go out slowly, instead of just clicking off. He talks about how the brain relates this to the experience of being in a cinema. It isn't a conscious thought, he notes, but a feeling. The brain is preparing us for an experience it thinks is going to be similar to the one before it and good design, art or music takes advantage of this.
      </li>
    </ul>
    <h3>Extreme Examples</h3>
    <p>
      I will now demonstrate the use of the model using some made up extreme examples. I am not using case studies because that would require in depth knowledge of a personʼs psychological makeup and this is not an exercise in comparative cognitive psychology. The examples can only be thought of as a kind of paradigm of the experience of music and values are not given for this reason. The triangles are equilateral for this purpose only.
    </p>
    <p>
      In the following section, when I place an example experience on the Trinity diagram, we are calling it music, but the theory works practically if we take that when we call an experience music, we are placing it somewhere on the Trinity.
    </p>
    <h4>Music which is extremely redundant & extremely emotionally relevant</h4>
    <img src="diagram2.png" class="diagram" />
    <p>
      Diagram 2a shows a piece of music is both extremely redundant and emotionally relevant. This is when a listener has had the same musical experience so many times that it almost does not stimulate them at all, but there is Emotional Relevance which is giving them a different appreciation of the music. Perhaps a bride who has heard her favourite song so many times she almost sick of it, (any more Redundant, and this experience would be off the reach of the Trinity and be classed as Noise) has her first dance with her groom to a piece and despite the piece still being redundant, itʼs Emotional Relevance stays with her.
    </p>
    <h4>Music which is extremely entropic & emotionally relevant</h4>
    <img src="diagram3.png" class="diagram" />
    <p>
      Diagram 2b shows that when a piece of music is both extremely entropic and emotionally relevant, it lies closest to the Redundancy corner. This is music which is almost noise, but has been given the title of music. An example which for most people would be in this area is a loved one performing a piece of music that they have composed in which the listener in question has never heard the likes of. Perhaps a father whose musical knowledge does not venture past Radio One has a son who composes avant-garde Classical music. There will still be a lot of Emotional Relevance to the listener because of the context of the experience, but it is barely music to the fatherʼs ears.
    </p>
    <h4>Extreme example of Entropy and Redundancy, with almost no Emotional Relevance</h4>
    <img src="diagram4.png" class="diagram" />
    <p>
      Sometimes music just doesnʼt click. The piece reminds you of other great music enough to make you feel comfortable, has enough of itʼs own ideas to keep you interested, but thereʼs nothing about it that you can really relate to emotionally. This is the position being illustrated in Diagram 2c.
    </p>
    <h3>Iʼm So Tired (How Time Affects The Trinity)</h3>
    <p>
      Maconie (1997: 23) problematizes Chomsky's preference of studying static reality rather than dynamic one:
    </p>
    <blockquote>
      <p>
        "A world in motion is only negotiable in approximate terms. It relies to a great extent on instinct. A dynamic world is highly unpredictable. It relies to a great extent on strategies of damage limitation. The accent is on survival, not truth; moving around obstacles, not ignoring them. We are asked to believe that being transported, whether by bicycle or by Beethoven, is not congenial to serious reflection on the mind and it's works."
      </p>
    </blockquote>
    <p>
      He continues that philosophers of the 20th century preferred the static world in general and states this focus as one reason music has been understudied.
    </p>
    <img src="diagram5.png" class="diagram" />
    <p>
      In the Holy Trinity, Emotional Relevance affects the Time threshold, and the Time threshold dictates how long a piece of music can be enjoyed for. This works because the higher the Emotional Relevance of a piece, the longer it takes to become Redundant. The more you like a song, the longer it takes to become bored of it.
    </p>
    <h3>Getting Better All The Time (When The Trinity Is Reversed)</h3>
    <p>
      So the more you listen to a piece, the quicker you get bored of it. It makes sense then, for the reverse to also be true: When you are not listening to a piece itʼs being pushed further into Entropy, but the more Emotional Relevance it has, the longer this will take. The more you like a song, the more you will remember it.19
    </p>
    <h4>Incubation Time</h4>
    <img src="diagram6.png" class="diagram" />
    <p>
      This “incubation time”20 is an important part of a personʼs relationship with a piece of music, as it helps keep the music in the middle of the triangle, i.e., the listener does not get bored of it.
    </p>
    <h3>Other Variables</h3>
    <p>
      Some additional variables to the Model I do not have the word count to discuss at length are:
    </p>
    <ul>
      <li>
        The personʼs mood. (Sensitive mood could allow for a higher Redundancy and Emotional threshold, etc.)
      </li>
      <li>
        Kennettʼs (2003:208) “Time-specific listening... the effects that the distance between the time-period in which the music was produced and the present time of listening may have.”
      </li>
      <li>
        Musical Training. Studies show this greatly changes how people appreciate music. E.g. MEG scans show neural responses to piano tones are significantly larger in musicians than non-musicians, with an even greater effect with instruments that the musician plays. (Peretz & Satorre, 2005, pp. 103) Additionally, musicians are found to detect tempo more accurately. (Krause et al, 2010) Seymour (2011) also discusses this idea.
      </li>
    </ul>
    <h3>Conclusion</h3>
    <p>
      I have created a model for analysing the effect of music. In a practical setting, this model can explain why certain musical experiences bring about superlative emotions of the divine in some, while others hear noise.
    </p>
    <p>
      Music affects our brain on many more levels then language does, but the message will always get lost without a clear semantic construct, be it musical or language based. This is why songs, which are after all a combination of music and words, have the potential to be a communicative medium in a unique way. Personally, I use music to help feel both new and familiar versions of any of the plethora of emotions available to me as a human, whereas I look to language to help me think about new things. Music connects people because it works on different levels, with the same experience sitting in a similar place in peopleʼs individual triangles.
    </p>
    <p>
      Iʼve used Beatles song titles to reinforce the thoughts behind this thesis, but this will not have resonated with all readers. The Beatles influence can be heard in all modern Pop music because any musician appealing to a mass market knows, even if subconsciously, that straying too far from conventions - being too Entropic - results in noise, while knowing that being overly Redundant is just as null. Never forgetting though, that Emotional Relevance is key.
    </p>
    <blockquote>
      <p>
        “[My music is a] compromise between the too difficult and the too easy: they are very brilliant, pleasant to the ear, natural without falling into the trap of emptiness. Here and there only experts can gain satisfaction but even non experts will feel pleasure without knowing why.”
      </p>
      <footer>
        Mozart, in a letter to his father, 1782
      </footer>
    </blockquote>
    <p>
      Lennon/McCartney, to Mozart, to the countless others connecting with people right now, they all do something thatʼs almost as statistically impossible as The Big Bang itself. Musicians throw atoms around, hoping they have the right ratio to create life. Great musicians strike a Balance through The Holy Trinity of Music Taste.
    </p>


    <h3>Bibliography</h3>
    <h4>References and background reading</h4>
    <ul>
      <li>Cooke, D. (1959) “The Language Of Music” Oxford University Press. London, New York & Toronto.</li>
      <li>Cross, I. (2004) “Music and Meaning, Ambiguity and Evolution.” Appears in Musical Communication, eds. D. Miell, R. Macdonald & D. Hargreaves, O.U.P 2004. University of Cambridge, Cambridge.</li>
      <li>Frith, S. (1998) “Performing Rites: Evaluating Popular Music” Oxford University Press. Oxford and New York.</li>
      <li>Kivy, P (2007) “Music, Language and Congnition.” Oxford University Press, Oxford and New York.</li>
      <li>Levitin, D (2009a) “The World In Six Songs.” Aurum Press, London.</li>
      <li>Levitin, D (2007) “This Is Your Brain On Music: Understanding a Human Obsession.” London: Grove/Atlantic.</li>
      <li>Maconie, R (1997) “The Science Of Music” Clarendon Press, Oxford.</li>
      <li>Meyer, L (1989) “Style and Music.” The University of Chicago Press, London and Chicago.</li>
      <li>Meyer, L (1961) “Emotion and Meaning In Music.” The University of Chicago Press, London and Chicago.</li>
      <li>Nietzsche, F. (1889) “Twilight Of The Idols” Republished and translated by Penguin Classics in 1990. [full online translation available at: http://www.handprint.com/SC/NIE/ GotDamer.html]</li>
      <li>Pinker, S. (1997) “How The Mind Works” Norton, New York.</li>
      <li>Petty, G. (2006) “Evidence Based Teaching” Nelson Thornes. (More information on the ICEDIP concept available at: < http://www.geoffpetty.com/downloads/WORD/ CreativeProcess.doc>)</li>
      <li>Sacks, O. (2007) “Musicophilia: Tales of Music and the Brain” Picador, London.</li>
      <li>Seeliger-Morley, I (2007?) “The 3D-AB Model.” University of Westminster, London</li>
      <li>Snyder, B (2000) “Music and Memory: An Introduction” Massachusetts Institute of Technology</li>
      <li>Storr, A. (1992) “Music and the Mind” Harper Collins, London.</li>
    </ul>

    <h4>Journals, Articles and Web References</h4>
    <ul>
      <li>Abbot, A. (2002) “Music, Maestro, Please!” Nature Magazine, Vol. 416. 7 March, 2002. pp.12-14</li>
      <li>Altenmüller, E.O. (2001) “How Many Music Centers Are There In The Brain?” Ann NY Acad Sci. 2011 June;930:273-80. Germany.</li>
      <li>Balter, M. (2001) “What Makes The Mind Dance and Count” Science, New Series. Vol. 292. No. 5522. June 1, 2001. pp.1636-1637</li>
      <li>Bharucha, J.; McFerrin, B.; Levitin, D.; Parsons, L.; Schaefer, J. (2010) “Notes & Neurons: In Search Of A Common Chorus” World Science Festival. Filmed June 2010, Posted September 2010. [Available at: http://worldsciencefestival.com/videos/notes_neurons_in_search_of_the_common_chorus?/video/notes-neurons-full ]</li>
      <li>Cervellin, G., Lippi, G. (2011) “From Music-Beat to Heart-Beat: A Journey in the Complex Interactions Between Music, Brain and Heart.” European Journal of Internal Medicine 22 pp. 371-374</li>
      <li>Chordia, P. & Rae, A. (2007) "Modeling and visualizing tonality in North Indian classical music." In Neural Information Processing Systems,Music Brain Workshop. [Available at: http://paragchordia.com/papers/nips07raagCamera.pdf ]
      </li>
      <li>Dutton, D. (2010) “A Darwinian Theory Of Beauty” Filmed February 2010 [Available at: http://www.ted.com/talks/denis_dutton_a_darwinian_theory_of_beauty.html]
      </li>
      <li>Groussard, M; Rauchs, G; Landeau, B; Viader, F; Desgranges, B; Eustache, F; Platel, H. (2010) “The Neural Substrates of Musical Memory Revealed by fMRI and Two Semantic Tasks” NeuroImage 53 (2010) pp. 1301-1309
      </li>
      <li>Hachinski, K.V., Hachinski, V. (1994) “The Brain and Music” Canada Medical Association Journal 1994: 151 (3) pp. 294-296
      </li>
      <li>Holden, C., (2001) “How The Brain Understands Music” Science, New Series. Vol. 292, No. 5517 (Apr. 27, 2001) p.623
      </li>
      <li>Janata, P.; Jeffery L. B.; Van Horn, J.D.; Leman, M.; Tillmann, B.; Bharucha, J.J. (2002) “The Cortical Topography of Tonal Structures Underlying Western Music” Science Magazine, Vol 298, 13 December 2002. pp.2167-2170
      </li>
      <li>Kennet, C. (2003) “Is Anybody Listening?” Analysing Popular Music (Edited by Allan F. Moore) Cambridge University Press. pp.196-217
      </li>
      <li>Kennett, C. (2008) “A Tribe Called Chris.” Open Space Magazine, London.</li>
      <li>Kilby, P. (2011) “If a ʻdisguisedʼ celebrity busker delights us, has beauty transcended the tube?” The Guardian - Tuesday, 29 November, 2011. [Available at: http://www.guardian.co.uk/commentisfree/2011/nov/29/disguised-celebrity-busker-katherine-jenkins?fb=native&CMP=FBCNETTXT9038]
      </li>
      <li>Koelsch, S., Siebel, W.A. (2005) “Towards a Neural Basis of Music Perception.” Trends in Cognitive Sciences. Vol. 9. No.12, December 2005. pp. 577-584
      </li>
      <li>Koelsch, S. (2010) “Towards a Neural Basis of Music-Evoked Emotions” Trends in Cognitive Sciences. Vol. 14, No. 3. pp. 131-137</li>
      <li>Koelsch, S; Kasper, E; Sammler, D; Schulze, K; Gunter, T; Friederici, A.D. (2004) Nature Neuroscience. Volume 7, Number 3, March 2004. pp.302-307</li>
      <li>Krause, V.; Schnitzler, A; Pollok, B. (2010) “Functional Network Interactions During Sensorimotor Synchronization in Musicians and Non-Musicians” NeuroImage 52 (2010) 245-251. Elsevier. Germany.
      </li>
      <li>Krumhansl, C.L. (2000) “Cross-Cultural Music Cognition: Cognitive Methodology Applied To North Sami Yoiks.” University of Jyvaskyla, Finland.
      </li>
      <li>Large, E.W., Snyder. J.S. (2009) “Pulse and Meter as Neural Resonance” The Neurosciences and Music III- Disorders and Plasticity: Ann. N.Y. Acad. Sci. 1169: 46-47
      </li>
      <li>Levitin, D. (2009b) “The Music Instinct” PBS. First broadcast in USA, 24/06/2009, 9pm. [More information available at: http://www.pbs.org/wnet/musicinstinct/about/]
      </li>
      <li>Luce, R. D. (2003) “Whatever Happened to Information Theory in Psychology?” Review of General Psychology 2003, Vol. 7, No.2, 183-188
      </li>
      <li>Morgan, K.A; Anthony, W.H; Luscombe, G; Tran, Y; Herkes, G; Bartrop, R.W. (2010) “The Effect of Music on Brain Wave Functioning During an Acute Psychotic Episode: A Pilot Study” Psychiatry Research 178 (2010) 446-448. Elsevier. Australia.
      </li>
      <li>Mueller, K; Mildner, T; Fritz, T; Lepsien, J; Schwarzbauer, C; Schroeter, M. L; Moeller, H. E. (2011) “Investigating Brain Response To Music: A Comparison of Different fMRI Acquisition Schemes” NeuroImage 54 (2011) 337-343 Elsevier. Germany and Scotland.
      </li>
      <li>Narmour, E. (1989) “The ʻGenetic Codeʼ of Melody: Cognitive Structures Generated by the Implication-Realisation Model” Contemporary Music REview, 4:1. pp. 45-63
      </li>
      <li>Norton, A; Winner, E; Cronin, K; Overy, K; Lee, D.J; Schlaug, G. (2005) “Are There Pre- Existing Neural, Cognitive, or Motoric Markers For Musical Ability?” Brain and Cognition, 59. 2005. pp. 124-134
      </li>
      <li>Patel, A.D (2003) “Language, Music, Syntax and the Brain” Nature Neuroscience. Volume 6, Number 7. July 2003.
      </li>
      <li>Perani, D; Saccuman, M.C; Scifo, P; Spada, D; Andreolli, G; Rovelli, R; Baldoli, C; Koelsch, S. (2010) “Functional Specializations For Music Processing In The Human Newborn Brain” PNAS, Vol. 107, No. 10. March 9, 2010. 4758-4763
      </li>
      <li>Peretz, I. (2001) “Brain Specialization for Music: New Evidence from Congential Amusia” Annals of the New York Academy of Sciences, New York.
      </li>
      <li>Peretz, I. & Zatorre, R.J. (2005) “Brain Organization For Music Processing.” Annu. Rev. Psychol. 56:89:114. Montreal.
      </li>
      <li>Ross, L. D., Amabile, T. M. Steinmetz, J. L. (1977) “Social roles, social control, and biases in social-perception processes.” Journal of Personality and Social Psychology, Vol 35(7), Jul, 1977. pp. 485-494
      </li>
      <li>Seymour, R. (2011) “How Beauty Feels” TEDSalon, Filmed May 2011. [Available at:
      http://www.ted.com/talks/richard_seymour_how_beauty_feels.html with full transcript]</li>
      <li>Shannon, C. E. (1948) “A Mathematical Theory of Communication.” The Bell System Technical Journal, vol. 27, pp. 379–423, 623-656. [Available at: http://cm.bell-labs.com/ cm/ms/what/shannonday/shannon1948.pdf ]</li>
      <li>Tramo, M.J. (2001) “Music of the Hemispheres.” Science, New Series. Vol. 291, No. 5501 (Jan. 5, 2001), pp. 54-56
      </li>
      <li>Weinberger, N.M (2004) “Music and the Brain” Scientific American, November 2004. pp. 88-95
      </li>
      <li>Wieser, H.G., (2003) “Music and the Brain” Ann. N.Y. Acad. Sci. 999: pp. 76-94 New York Academy of Sciences
      </li>
      <li>Wigglesworth, M. (2011) “What Makes Some Works More Popular Than Others?” Gramophone Magazine, online edition. [Available at: http://www.gramophone.co.uk/ blog/shaping-the-invisible/et-nova-et-vetera]
      </li>
    </ul>
    <h3>Glossary</h3>
    <ul>
      <li>
        fMRI - A type of specialized MRI scan used to measure the hemodynamic response (change in blood flow) related to neural activity in the brain or spinal cord of humans or other animals.
      </li>
      <li>
        MEG - Magnetoencephalography (MEG) is a technique for mapping brain activity by recording magnetic fields produced by electrical currents occurring naturally in the brain, using arrays of SQUIDs (superconducting quantum interference devices).
      </li>
      <li>
        MRI - Medicinal imaging technique used in radiology to visualize detailed internal structures.
      </li>
      <li>
        SOM Model - A self-organizing map (SOM) or self-organizing feature map (SOFM) is a type of artificial neural network that is trained using unsupervised learning to produce a representation of the input space of the training samples, called a map.
      </li>
    </ul>

    <div class="footnotes">
      <h3>Footnotes</h3>
      <sub id="f1">1</sub>
      <p>
        It could be said that the writings of Classical music theorists such as those mentioned come from a misconception that music affects us all the same way. Psychologists call this The Fundamental Attribution Error (see Ross, L. D., Amabile, T. M. Steinmetz, J. L. (1977)) - that it is human nature to assume that an individual who acts in a different way to us is doing so because of a difference in internal factors (such as personality) rather than external factors (such as circumstance). As well classical music theorists, many modern musicians still forget that the basic fact that people experience the world differently.
      </p>
      <sup><a href="#r1">Back to text ↩</a></sup>
      <sub id="f2">2</sub>
      <p>
        Meyer (1961) goes further in depth into the various viewpoints which Iʼve somewhat generalized here. Within pp.1-4, he contrasts ʻabsolutistsʼ with ʻreferentialistsʼ (whether or not music can be about/reference anything other than itself) and ʻformalistsʼ with ʻexpressionistsʼ (whether or not music is an intellectual or an emotional exercise). These distinctions are important to remember when understanding the Classicists viewpoint but my points still stand. Meyer does go on to hint at and even dissect this problem but neglects to see how his own writing fits into the errors which he calls ʻhedonismʼ, ʻatomismʼ and ʻuniversalismʼ. Although he talks much about the emotional response of music, he fails to really define how that effect can be personal to a given individual.
      </p>
      <sup><a href="#r2">Back to text ↩</a></sup>
      <sub id="f3">3</sub>
      <p>
        However, it is worth noting that the studies of music on the brain are very much ongoing with increasingly focussed methodology, as demonstrated by very recent studies into different fMRI acquisition schemes in relation to neuro-musicology. (Mueller et al., 2011)
      </p>
      <sup><a href="#r3">Back to text ↩</a></sup>

      <sub id="f4">4</sub>
      <p>
        Although it could be argued that birdsong serves the same purpose as our music, as Storr (1992, pp.5) points out. “Birds sing far more than is biologically necessary for the various forms of communication.”
      </p>
      <sup><a href="#r4">Back to text ↩</a></sup>

      <sub id="f5">5</sub>
      <p>
        As opposed to language which is always ʻaboutʼ a specific thing. As Cross (ibid, pp.4) goes on, “Indeed, aboutness, or intentionality can be considered intrinsic to any act of communication.”
      </p>
      <sup><a href="#r5">Back to text ↩</a></sup>

      <sub id="f6">6</sub>
      <p>
        Although neuromusicology was a very new field at the time of the works mentioned.
      </p>
      <sup><a href="#r6">Back to text ↩</a></sup>

      <!-- from here the footnotes are 1 out of sync with the source because of a missing on -->
      <sub id="f7">7</sub>
      <p>
        It could be argued that this knowledge makes the fact that pop music generally follows conventional rhythms.
      </p>
      <sup><a href="#r7">Back to text ↩</a></sup>

      <sub id="f8">8</sub>
      <p>In particular, the North Indian Classical Raag, which are contrasted with Western keys by Chordia & Rae, (2007, pp.1-2). The authors also cite Tillman and Ardmanʼs “speeded judgments made after listening to a melody or chord sequence in a well defined key were more accurate and faster for tones belonging to that key, and in some cases reaction times were roughly inversely proportional to prevalence of the tone on the key context. These experiments show that tonal schemes are indeed internalized by listeners.”</p>
      <sup><a href="#r8">Back to text ↩</a></sup>

      <sub id="f9">9</sub>
      <p>
        Based on <a href="http://thesaurus.com/browse/subjective?r=76&src=ref&ch=the">thesaurus.comʼs defintion of 'subjective'.</a>
      </p>
      <sup><a href="#r9">Back to text ↩</a></sup>

      <sub id="f10">10</sub>
      <p>
        “<a href="http://www.goodreads.com/ book/show/8250490-my-ancestor-was-an-ancient-astronaut">My Ancestor Was An Ancient Astronaut</a>”, Tony Beta, 2011.
      </p>
      <sup><a href="#r10">Back to text ↩</a></sup>

      <sub id="f11">11</sub>
      <p>
        "Understanding" here meaning to enjoy and appreciate the construction of it. (ibid, pp217)
      </p>
      <sup><a href="#r11">Back to text ↩</a></sup>

      <sub id="f11">12</sub>
      <p>
        “Syntax may be defined as a set of principles governing the combination of discrete structural elements (such as words or musical tones) into sequences).” (Patel, 2003)
      </p>
      <sup><a href="#r12">Back to text ↩</a></sup>

      <sub id="f13">13</sub>
      <p>
        This viewpoint holds that (at least basic) human emotions, mounting evidence suggests, are universal but emotional response from music is not. Rather, musical response is culturally specific. (ibid, pp. 221) However, I would contest that the truth is more complex than this and that some aspects of music are more culturally widespread than others. This could also be possible of emotions in general, but may be hard to back up and may not even be relevant.
      </p>
      <sup><a href="#r13">Back to text ↩</a></sup>

      <sub id="f14">14</sub>
      <p>
        e.g Wagners Tristan chord. In context of the the opera “Tristan Und Isolde” the chord represents Tristanʼs longing for Isolde, but out of context most people would treat it the same as just a dissonant chord. In contrast, when somebody speaks English itʼs assumed theyʼre following the standards of the Dictionary. The context and set of rules within it are widely established.
      </p>
      <sup><a href="#r14">Back to text ↩</a></sup>

      <sub id="f15">15</sub>
      <p>
        Although Cross favors Western examples - “Members of a recreation choir, or of an amateur rock band, may rarely if ever fulfil the role of performer” pp. 3
      </p>
      <sup><a href="#r15">Back to text ↩</a></sup>

      <sub id="f16">16</sub>
      <p>
        The diagrams are based on Ternary Plot graphs, which are mostly used in mineralogy and petrology. They follow a similar logic in that, we are plotting the thing in question on a triangle, and the further away it is from a named point, the less of that quality it has is included. More information on Ternary Plot Graphs can be found in Will Vaughnʼs 5 September 2010 online article “Ternary Plots” available at [http:// wvaughan.org/ternaryplots.html] (Retrieved 20/11/2011)
      </p>
      <sup><a href="#r16">Back to text ↩</a></sup>

      <sub id="f17">17</sub>
      <p>
        Contextual emotional relevance refers to the delivery of the musical experience. I touched on talking about the volume above, but also in consideration is all acoustical properties of the listening medium and environment. Is it live? How far away is the listener from the sound source? (Kennet, 2003:208 breaks this up into Intensity-specific listening and Locus-specific listening) In our modern culture, the performer (or the story surrounding the performer) of a piece holds a massive amount of Emotional Relevance to our experience of music, as discussed in a recent Guardian article. (Kilbey, 2011)
      </p>
      <sup><a href="#r17">Back to text ↩</a></sup>

      <sub id="f18">18</sub>
      <p>
        Levitin (2009a) posited one possible origin of music as a method for making potential mates remember each other.
      </p>
      <sup><a href="#r18">Back to text ↩</a></sup>

      <sub id="f19">19</sub>
      <p>
        Name taken from the ICEDIP theory of the Creative Process (Petty, 2006).
      </p>
      <sup><a href="#r19">Back to text ↩</a></sup>

    </div>
  </body>
</html>
